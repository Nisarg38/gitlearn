# gitlearn - Learn from merged PRs and keep AI context files fresh
# https://github.com/Nisarg38/gitlearn
#
# Setup (2 steps):
#   mkdir -p .github/workflows && curl -o .github/workflows/gitlearn.yml https://raw.githubusercontent.com/Nisarg38/gitlearn/main/.github/workflows/gitlearn.yml
#   gh secret set ANTHROPIC_API_KEY  # or OPENAI_API_KEY, OPENROUTER_API_KEY
#
# Auto-detects provider from your secret name. That's it!
#
# Default models (all with thinking/reasoning enabled):
#   Anthropic: claude-sonnet-4-5-20250929 + extended thinking (10k tokens)
#   OpenAI: gpt-5.2-codex
#   OpenRouter: moonshotai/kimi-k2.5
#
# Model configuration (repository variables):
#   GITLEARN_MODEL: Override default model
#   GITLEARN_MAX_TOKENS: Max output tokens (default: 1024)
#   GITLEARN_TEMPERATURE: Temperature 0-1 (default: not set, uses model default)
#   GITLEARN_THINKING_BUDGET: Extended thinking tokens for Claude (enables deep reasoning)
#   GITLEARN_REASONING_EFFORT: OpenAI reasoning effort: low|medium|high (for o1/o3 models)
#   GITLEARN_API_BASE: Custom endpoint (uses OpenAI-compatible format)

name: gitlearn

on:
  pull_request:
    types: [closed]
    branches: [main, master]

jobs:
  learn:
    if: github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    env:
      # Standard API keys - just use the one you have
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      # Model configuration
      GITLEARN_MODEL: ${{ vars.GITLEARN_MODEL }}
      GITLEARN_MAX_TOKENS: ${{ vars.GITLEARN_MAX_TOKENS }}
      GITLEARN_TEMPERATURE: ${{ vars.GITLEARN_TEMPERATURE }}
      GITLEARN_THINKING_BUDGET: ${{ vars.GITLEARN_THINKING_BUDGET }}
      GITLEARN_REASONING_EFFORT: ${{ vars.GITLEARN_REASONING_EFFORT }}
      GITLEARN_API_BASE: ${{ vars.GITLEARN_API_BASE }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect provider
        id: provider
        run: |
          # Initialize defaults
          DEFAULT_THINKING=""
          DEFAULT_REASONING=""

          # Custom endpoint overrides provider detection
          if [ -n "$GITLEARN_API_BASE" ]; then
            # Use whichever key is available with custom endpoint
            if [ -n "$OPENAI_API_KEY" ]; then
              API_KEY="$OPENAI_API_KEY"
            elif [ -n "$ANTHROPIC_API_KEY" ]; then
              API_KEY="$ANTHROPIC_API_KEY"
            elif [ -n "$OPENROUTER_API_KEY" ]; then
              API_KEY="$OPENROUTER_API_KEY"
            fi
            echo "provider=custom" >> $GITHUB_OUTPUT
            echo "api_key=$API_KEY" >> $GITHUB_OUTPUT
            echo "model=${GITLEARN_MODEL:-gpt-4o}" >> $GITHUB_OUTPUT
            echo "Using custom endpoint: $GITLEARN_API_BASE"
          elif [ -n "$ANTHROPIC_API_KEY" ]; then
            echo "provider=anthropic" >> $GITHUB_OUTPUT
            echo "api_key=$ANTHROPIC_API_KEY" >> $GITHUB_OUTPUT
            echo "model=${GITLEARN_MODEL:-claude-sonnet-4-5-20250929}" >> $GITHUB_OUTPUT
            DEFAULT_THINKING="10000"  # Extended thinking by default
            echo "Using Anthropic with extended thinking"
          elif [ -n "$OPENAI_API_KEY" ]; then
            echo "provider=openai" >> $GITHUB_OUTPUT
            echo "api_key=$OPENAI_API_KEY" >> $GITHUB_OUTPUT
            echo "model=${GITLEARN_MODEL:-gpt-5.2-codex}" >> $GITHUB_OUTPUT
            echo "Using OpenAI"
          elif [ -n "$OPENROUTER_API_KEY" ]; then
            echo "provider=openrouter" >> $GITHUB_OUTPUT
            echo "api_key=$OPENROUTER_API_KEY" >> $GITHUB_OUTPUT
            echo "model=${GITLEARN_MODEL:-moonshotai/kimi-k2.5}" >> $GITHUB_OUTPUT
            echo "Using OpenRouter"
          else
            echo "::error::No API key found. Add one of: ANTHROPIC_API_KEY, OPENAI_API_KEY, OPENROUTER_API_KEY"
            exit 1
          fi

          # Pass through model config
          echo "max_tokens=${GITLEARN_MAX_TOKENS:-1024}" >> $GITHUB_OUTPUT
          echo "temperature=${GITLEARN_TEMPERATURE:-}" >> $GITHUB_OUTPUT
          echo "thinking_budget=${GITLEARN_THINKING_BUDGET:-$DEFAULT_THINKING}" >> $GITHUB_OUTPUT
          echo "reasoning_effort=${GITLEARN_REASONING_EFFORT:-$DEFAULT_REASONING}" >> $GITHUB_OUTPUT

      - name: Setup context files
        id: setup
        run: |
          CHANGES_MADE=false

          # First-time setup: no context files exist
          if [ ! -f claude.md ] && [ ! -f agents.md ]; then
            cat > claude.md << 'EOF'
# Project Context

## Overview
<!-- Add project description -->

## Learnings
EOF
            ln -s claude.md agents.md
            CHANGES_MADE=true
            echo "Created initial claude.md and agents.md symlink"

          # Only agents.md exists: rename to claude.md
          elif [ ! -f claude.md ] && [ -f agents.md ]; then
            mv agents.md claude.md
            ln -s claude.md agents.md
            CHANGES_MADE=true
            echo "Renamed agents.md to claude.md, created symlink"

          # Both exist but agents.md is not a symlink
          elif [ -f agents.md ] && [ ! -L agents.md ]; then
            echo "needs_merge=true" >> $GITHUB_OUTPUT
            echo "Both files exist, need to merge"

          # Only claude.md exists: create symlink
          elif [ ! -e agents.md ]; then
            ln -s claude.md agents.md
            CHANGES_MADE=true
            echo "Created agents.md symlink"
          else
            echo "Files already set up correctly"
          fi

          echo "changes_made=$CHANGES_MADE" >> $GITHUB_OUTPUT

      - name: Merge existing files
        if: steps.setup.outputs.needs_merge == 'true'
        env:
          API_KEY: ${{ steps.provider.outputs.api_key }}
          PROVIDER: ${{ steps.provider.outputs.provider }}
          MODEL: ${{ steps.provider.outputs.model }}
          MAX_TOKENS: ${{ steps.provider.outputs.max_tokens }}
          TEMPERATURE: ${{ steps.provider.outputs.temperature }}
          THINKING_BUDGET: ${{ steps.provider.outputs.thinking_budget }}
          REASONING_EFFORT: ${{ steps.provider.outputs.reasoning_effort }}
        run: |
          CLAUDE_CONTENT=$(cat claude.md)
          AGENTS_CONTENT=$(cat agents.md)

          PROMPT="Merge these AI context files. Dedupe, keep all unique info, preserve formatting.

FILE 1 (claude.md):
$CLAUDE_CONTENT

FILE 2 (agents.md):
$AGENTS_CONTENT

Output only the merged markdown content, nothing else."

          if [ "$PROVIDER" = "anthropic" ]; then
            # Build Anthropic request with optional extended thinking
            if [ -n "$THINKING_BUDGET" ]; then
              REQUEST=$(jq -n \
                --arg model "$MODEL" \
                --arg prompt "$PROMPT" \
                --argjson max_tokens 16384 \
                --argjson budget "$THINKING_BUDGET" \
                '{
                  model: $model,
                  max_tokens: $max_tokens,
                  thinking: { type: "enabled", budget_tokens: $budget },
                  messages: [{role: "user", content: $prompt}]
                }')
            else
              REQUEST=$(jq -n \
                --arg model "$MODEL" \
                --arg prompt "$PROMPT" \
                --argjson max_tokens "${MAX_TOKENS:-4096}" \
                '{model: $model, max_tokens: $max_tokens, messages: [{role: "user", content: $prompt}]}')

              # Add temperature if set
              if [ -n "$TEMPERATURE" ]; then
                REQUEST=$(echo "$REQUEST" | jq --argjson temp "$TEMPERATURE" '. + {temperature: $temp}')
              fi
            fi

            RESPONSE=$(curl -s https://api.anthropic.com/v1/messages \
              -H "x-api-key: $API_KEY" \
              -H "anthropic-version: 2023-06-01" \
              -H "content-type: application/json" \
              -d "$REQUEST")

            # Extract text from response (handle both thinking and non-thinking formats)
            MERGED=$(echo "$RESPONSE" | jq -r '.content | map(select(.type == "text")) | .[0].text // empty')
          else
            case "$PROVIDER" in
              openai) ENDPOINT="https://api.openai.com/v1/chat/completions" ;;
              openrouter) ENDPOINT="https://openrouter.ai/api/v1/chat/completions" ;;
              custom) ENDPOINT="${GITLEARN_API_BASE}/chat/completions" ;;
            esac

            # Build OpenAI-compatible request
            REQUEST=$(jq -n \
              --arg model "$MODEL" \
              --arg prompt "$PROMPT" \
              --argjson max_tokens "${MAX_TOKENS:-4096}" \
              '{model: $model, max_tokens: $max_tokens, messages: [{role: "user", content: $prompt}]}')

            # Add temperature if set
            if [ -n "$TEMPERATURE" ]; then
              REQUEST=$(echo "$REQUEST" | jq --argjson temp "$TEMPERATURE" '. + {temperature: $temp}')
            fi

            # Add reasoning_effort for OpenAI o1/o3 models
            if [ -n "$REASONING_EFFORT" ]; then
              REQUEST=$(echo "$REQUEST" | jq --arg effort "$REASONING_EFFORT" '. + {reasoning_effort: $effort}')
            fi

            MERGED=$(curl -s "$ENDPOINT" \
              -H "Authorization: Bearer $API_KEY" \
              -H "Content-Type: application/json" \
              -H "HTTP-Referer: https://github.com/${{ github.repository }}" \
              -d "$REQUEST" | jq -r '.choices[0].message.content')
          fi

          if [ -n "$MERGED" ] && [ "$MERGED" != "null" ]; then
            echo "$MERGED" > claude.md
            rm agents.md
            ln -s claude.md agents.md
            echo "Successfully merged files"
          else
            echo "Warning: Merge failed, keeping original claude.md"
            rm agents.md
            ln -s claude.md agents.md
          fi

      - name: Generate learning
        id: learn
        env:
          API_KEY: ${{ steps.provider.outputs.api_key }}
          PROVIDER: ${{ steps.provider.outputs.provider }}
          MODEL: ${{ steps.provider.outputs.model }}
          MAX_TOKENS: ${{ steps.provider.outputs.max_tokens }}
          TEMPERATURE: ${{ steps.provider.outputs.temperature }}
          THINKING_BUDGET: ${{ steps.provider.outputs.thinking_budget }}
          REASONING_EFFORT: ${{ steps.provider.outputs.reasoning_effort }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          PR_NUM="${{ github.event.pull_request.number }}"
          PR_DIFF=$(gh pr diff $PR_NUM --repo ${{ github.repository }} 2>/dev/null | head -c 10000 || echo "Diff unavailable")

          # Build prompt
          PROMPT=$(cat << 'PROMPT_EOF'
Based on this merged PR, suggest a 1-3 line addition for the project AI context file. Focus on:
- Architectural decisions
- Code conventions or patterns
- Gotchas or edge cases future devs should know
- Important dependencies or configurations

Output ONLY the markdown snippet to append (can include a header if needed), or output exactly NONE if there's no meaningful learning worth documenting.

PROMPT_EOF
)
          PROMPT="$PROMPT
PR Title: ${{ github.event.pull_request.title }}

PR Description:
${{ github.event.pull_request.body }}

Code Changes:
$PR_DIFF"

          if [ "$PROVIDER" = "anthropic" ]; then
            # Build Anthropic request with optional extended thinking
            if [ -n "$THINKING_BUDGET" ]; then
              REQUEST=$(jq -n \
                --arg model "$MODEL" \
                --arg prompt "$PROMPT" \
                --argjson max_tokens 16384 \
                --argjson budget "$THINKING_BUDGET" \
                '{
                  model: $model,
                  max_tokens: $max_tokens,
                  thinking: { type: "enabled", budget_tokens: $budget },
                  messages: [{role: "user", content: $prompt}]
                }')
            else
              REQUEST=$(jq -n \
                --arg model "$MODEL" \
                --arg prompt "$PROMPT" \
                --argjson max_tokens "${MAX_TOKENS:-1024}" \
                '{model: $model, max_tokens: $max_tokens, messages: [{role: "user", content: $prompt}]}')

              if [ -n "$TEMPERATURE" ]; then
                REQUEST=$(echo "$REQUEST" | jq --argjson temp "$TEMPERATURE" '. + {temperature: $temp}')
              fi
            fi

            RESPONSE=$(curl -s https://api.anthropic.com/v1/messages \
              -H "x-api-key: $API_KEY" \
              -H "anthropic-version: 2023-06-01" \
              -H "content-type: application/json" \
              -d "$REQUEST")

            SUGGESTION=$(echo "$RESPONSE" | jq -r '.content | map(select(.type == "text")) | .[0].text // empty')
          else
            case "$PROVIDER" in
              openai) ENDPOINT="https://api.openai.com/v1/chat/completions" ;;
              openrouter) ENDPOINT="https://openrouter.ai/api/v1/chat/completions" ;;
              custom) ENDPOINT="${GITLEARN_API_BASE}/chat/completions" ;;
            esac

            REQUEST=$(jq -n \
              --arg model "$MODEL" \
              --arg prompt "$PROMPT" \
              --argjson max_tokens "${MAX_TOKENS:-1024}" \
              '{model: $model, max_tokens: $max_tokens, messages: [{role: "user", content: $prompt}]}')

            if [ -n "$TEMPERATURE" ]; then
              REQUEST=$(echo "$REQUEST" | jq --argjson temp "$TEMPERATURE" '. + {temperature: $temp}')
            fi

            if [ -n "$REASONING_EFFORT" ]; then
              REQUEST=$(echo "$REQUEST" | jq --arg effort "$REASONING_EFFORT" '. + {reasoning_effort: $effort}')
            fi

            SUGGESTION=$(curl -s "$ENDPOINT" \
              -H "Authorization: Bearer $API_KEY" \
              -H "Content-Type: application/json" \
              -H "HTTP-Referer: https://github.com/${{ github.repository }}" \
              -d "$REQUEST" | jq -r '.choices[0].message.content')
          fi

          # Handle empty or error responses
          if [ -z "$SUGGESTION" ] || [ "$SUGGESTION" = "null" ]; then
            SUGGESTION="NONE"
          fi

          echo "suggestion<<EOF" >> $GITHUB_OUTPUT
          echo "$SUGGESTION" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Update context PR
        if: steps.learn.outputs.suggestion != 'NONE' && !contains(steps.learn.outputs.suggestion, 'NONE')
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BRANCH="gitlearn/context-updates"

          git config user.name "gitlearn[bot]"
          git config user.email "gitlearn[bot]@users.noreply.github.com"

          # Checkout or create branch
          if git ls-remote --exit-code --heads origin $BRANCH 2>/dev/null; then
            git fetch origin $BRANCH
            git checkout $BRANCH
            git rebase origin/main || { git rebase --abort 2>/dev/null; git reset --hard origin/main; }
          else
            git checkout -b $BRANCH
          fi

          # Ensure setup changes are included
          if [ "${{ steps.setup.outputs.changes_made }}" = "true" ] || [ "${{ steps.setup.outputs.needs_merge }}" = "true" ]; then
            git add claude.md agents.md 2>/dev/null || true
          fi

          # Append learning with metadata comment
          echo "" >> claude.md
          echo "<!-- PR #${{ github.event.pull_request.number }} - $(date +%Y-%m-%d) -->" >> claude.md
          echo '${{ steps.learn.outputs.suggestion }}' >> claude.md

          git add claude.md agents.md
          git commit -m "ðŸ“š #${{ github.event.pull_request.number }}: ${{ github.event.pull_request.title }}" || {
            echo "No changes to commit"
            exit 0
          }

          git push origin $BRANCH --force-with-lease

          # Create PR if one doesn't exist
          if ! gh pr list --head $BRANCH --state open --json number | jq -e '.[0]' >/dev/null 2>&1; then
            gh pr create \
              --title "ðŸ¤– Context Updates" \
              --body "$(cat << 'PR_BODY'
Auto-accumulated learnings from merged PRs.

This PR is automatically updated each time a PR is merged. Review the changes to ensure quality context documentation.

**How it works:**
- Each merged PR is analyzed for architectural decisions, conventions, and gotchas
- Learnings are appended to `claude.md` (with `agents.md` as a symlink)
- Merge this PR when you're ready to update your AI context files

---
*Powered by [gitlearn](https://github.com/Nisarg38/gitlearn)*
PR_BODY
)" \
              --head $BRANCH \
              --base main \
              --label "gitlearn" 2>/dev/null || \
            gh pr create \
              --title "ðŸ¤– Context Updates" \
              --body "Auto-accumulated learnings from merged PRs." \
              --head $BRANCH \
              --base main
          fi

          echo "âœ… Context PR updated successfully"
